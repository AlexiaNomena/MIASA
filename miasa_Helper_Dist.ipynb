{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b26c252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Changes to local modules might not update if Kernel is not restarted'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Errors might remain if Kernel is not restarted\"\"\"\n",
    "\"\"\"Changes to local modules might not update if Kernel is not restarted\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada83d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Necessary modules \"\"\"\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from Methods.classify import split_data, plotClass, plotClass_separated, plotClass_separated_ver0\n",
    "from Methods.miasa_class import Miasa_Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d395ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Name and origin of dataset \"\"\"\n",
    "DataName = \"Distribution_data\"\n",
    "from Methods.simulate_class_data_final import generate_data_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b8b84de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Euclidean embedding pameters only used in MIASA (includes a finite number of auto adjustements)\n",
    "    \n",
    "    if custom, then type dictionary \n",
    "    c_dic = {\"c1\":float, \"c2\":float, \"c3\":float} \n",
    "\"\"\"\n",
    "c_dic = \"default\" \n",
    "\n",
    "\"\"\" Load or Generate data: \n",
    "    \n",
    "    Required:\n",
    "    X and Y are separated datasets with M, N samples, respectively, with each samples containing K realizations\n",
    "    X.shape = (M, K) \n",
    "    Y.shape = (N, K)\n",
    "    num_clust = number of clusters\n",
    "    dtp : tuple (datatype X_vars , datatype Y_vars) is needed for visualization only\n",
    "    \n",
    "\n",
    "    Not Required:\n",
    "    X_vars, Y_vars = Labels of X and Y samples\n",
    "    Class_True = True cluster labels of samples\n",
    "    \n",
    "\"\"\"\n",
    "#palette_true = \"husl\"# if custom_palette = False, used seaborn color palette parameter for true clusters \n",
    "\n",
    "# Customized color palette suitable for my simulated data\n",
    "import seaborn as sns\n",
    "n = 1\n",
    "cdist_1 = list(sns.color_palette(\"Reds\", 10+n*10)[10:][::n])\n",
    "cdist_2 = list(sns.color_palette(\"Greens\", 10+n*10)[10:][::n])\n",
    "cdist_3 = list(sns.color_palette(\"Blues\", 10+n*10)[10:][::n])\n",
    "cdist_4 = list(sns.color_palette(\"Purples\", 10+n*10)[10:][::n])\n",
    "palette_true = []\n",
    "for i in range(10):\n",
    "    palette_true += [cdist_1[i]] + [cdist_2[i]] + [cdist_3[i]] + [cdist_4[i]]\n",
    "\n",
    "data_dic_orig, class_dic, num_clust, dtp = generate_data_dist(var_data = False, \n",
    "                                                              palette = palette_true, #(make sure not to use cyclic color palette)\n",
    "                                                              custom_palette = True, \n",
    "                                                              random_state = 46)\n",
    "X, Y, Class_True, X_vars, Y_vars = split_data(data_dic_orig, class_dic, separation = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c26b746",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parameters of MIASA, first example\n",
    "\"\"\"\n",
    "\n",
    "metric_method = (\"eCDF\", \"KS-p1\") # (Similarity, Association) distance models\n",
    "clust_method = \"Agglomerative_ward\" # clustering aglorithm to use\n",
    "palette_pred = \"Dark2\" # seaborn color palette (make sure not to use cyclic color maps)\n",
    "dist_origin = (True,False) # for datasets (X, Y) decide if the distance to the origin of the axes is interpretable as the norm of the feature representations of the samples\n",
    "in_threads = False # True to avoid broken runs when using parallel jobs (relevant only for class_experiments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be975c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If desired custom similarity feature representation (defining Euclidean similarity distance) \n",
    "and association measures then \n",
    "\n",
    "1) set \n",
    "    metric_method = \"precomputed\"\n",
    "2) give Feature_dic as parameter\n",
    "    Feature_dic[\"Feature_X\"] : array similarity features of dataset X: M samples and L features, X.shape = (M, L)\n",
    "    Feature_dic[\"Feature_Y\"] : array similarity features of dataset Y: M samples and S features, Y.shape = (N, S)\n",
    "    Feature_dic[\"Asssociation_function\"] : a function of argument tuple full datasets (X, Y) or pair of samples (X_i, Y_j) computing the pairwise association between the samples of X and Y\n",
    "    \n",
    "    Feature_dic[\"assoc_func_type\"] : type of the association function as options\n",
    "                                    option 1: str vectorized     : argument full datasets (X, Y) => return directly the Asscociation distance matrix of shape (M, N) \n",
    "                                    option 2: str not_vectorized : argument samples (X_i, Y_j)   => return a scalar = Associaiton distance between sample X_i and sample Y_j\n",
    "\n",
    "    Feature_dic[\"DMat\"]  : array distance function, then Feature_dic[\"Asssociation_function\"] Feature_dic[\"assoc_func_type\"] can be set to None \n",
    "    Feature_dic[\"dist_origin\"]: bool tuple (X?, Y?) deciding if the distance to the origin of the axes is interpretable as the norm of the feature representations of the samples\n",
    "                                Must be in aggreement with given Feature_dic[\"DMat\"]\n",
    "                                if any (X?, Y?) then shape Feature_dic[\"DMat\"].shape = (M+N+1, M+N+1) and distance to origin is placed at the M+1-th row (see function Methods.Core.CosLM.Prox_Mat)\n",
    "\n",
    "example:\n",
    "    \n",
    "from Methods.Generate_Features import eCDF, get_assoc_func\n",
    "metric_method = \"precomputed\"\n",
    "Feature_dic = {} \n",
    "Feature_dic[\"Feature_X\"], Feature_dic[\"Feature_Y\"] = eCDF(X,Y)\n",
    "Feature_dic[\"Asssociation_function\"], Feature_dic[\"assoc_func_type\"] = get_assoc_func(\"KS-stat\")\n",
    "Feature_dic[\"DMat\"] = None \n",
    "Feature_dic[\"dist_origin\"] = (True,True) ## if DMat is not None it should contain distance to origin setting \n",
    "\"\"\"\n",
    "Feature_dic = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d38b46d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parameters of MIASA, second example and same as in the first example\n",
    "\"\"\"\n",
    "from Methods.Generate_Features import Moments_feature, Histogram_feature, get_assoc_func\n",
    "metric_method = \"precomputed\"\n",
    "clust_method = \"Agglomerative_ward\" # clustering aglorithm to use\n",
    "Feature_dic = {} \n",
    "\n",
    "import numpy as np\n",
    "Hist_Moms = lambda Z: np.concatenate((Histogram_feature(Z), Moments_feature(Z)), axis = 1)\n",
    "Feature_dic[\"Feature_X\"], Feature_dic[\"Feature_Y\"] = Histogram_feature(X), Histogram_feature(Y) #Moments_feature(X), Moments_feature(Y)\n",
    "Feature_dic[\"Asssociation_function\"], Feature_dic[\"assoc_func_type\"] = get_assoc_func(\"KS-p1\")\n",
    "Feature_dic[\"DMat\"] = None \n",
    "Feature_dic[\"dist_origin\"] = (True,True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "337a67dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacement matrix is PSD: success Euclidean embedding\n",
      "------------- Some checking ------------\n",
      "Number of True Clusters/Distributions 4 checked: True\n",
      "Number of True colors of clusters 20 checked non-cyclic: False\n",
      "Number of predicted clusters 4 checked: True\n",
      "Number of colors predicted clusters 4 checked non-cyclic: True\n",
      "------------- Evaluate clustering ------------\n",
      "Rand Index 0.8739502889833086 \n",
      "Adjusted Rand_Index 0.6964584204110192 \n",
      "Number of iterations 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Perform MIASA Classification of samples\n",
    "\"\"\"\n",
    "num_clust_test = num_clust ### identify famillies of distribution instead of distribution\n",
    "Id_Class = Miasa_Class(X, Y, num_clust = num_clust_test, \n",
    "                       dist_origin = dist_origin, \n",
    "                       metric_method = metric_method, \n",
    "                       clust_method = clust_method, # clustering based on Euclidean embedding and point of origin is not clustered (the characterisits of the embedding makes all points too far from it and it risk to be always considered as one independen cluster)\n",
    "                       c_dic = c_dic, Feature_dic = Feature_dic,\n",
    "                       in_threads = in_threads,\n",
    "                       palette = palette_pred)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "print(\"------------- Some checking ------------\")\n",
    "print(\"Number of True Clusters/Distributions\", len(np.unique(Class_True)), \"checked:\", num_clust == len(np.unique(Class_True)))\n",
    "num_col_true = (np.unique(pd.DataFrame(data_dic_orig[\"true_colors\"]).loc[:][:], axis = 1)).shape[1]\n",
    "print(\"Number of True colors of clusters\", num_col_true, \"checked non-cyclic:\", num_col_true == num_clust) \n",
    "\n",
    "print(\"Number of predicted clusters\", len(np.unique(Id_Class[\"Class_pred\"])), \"checked:\", num_clust == len(np.unique(Id_Class[\"Class_pred\"])))\n",
    "num_col_pred = (np.unique(Id_Class[\"color_clustered\"], axis = 0)).shape[0]\n",
    "print(\"Number of colors predicted clusters\", num_col_pred, \"checked non-cyclic:\", num_col_pred == num_clust) \n",
    "\n",
    "print(\"------------- Evaluate clustering ------------\")\n",
    "from sklearn.metrics import rand_score, adjusted_rand_score\n",
    "accuracy_2a = rand_score(Class_True, Id_Class[\"Class_pred\"])\n",
    "accuracy_3a = adjusted_rand_score(Class_True, Id_Class[\"Class_pred\"])\n",
    "\n",
    "print(\"Rand Index\", accuracy_2a, \"\\nAdjusted Rand_Index\", accuracy_3a, \"\\nNumber of iterations\", Id_Class[\"num_iterations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4cd3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2-Dimensional visualization of clusters (UMAP visualization) \n",
    "- all predicted classes \n",
    "- colored predicted classes or true classes \n",
    "\"\"\"\n",
    "pdf= PdfPages(\"Figures/\"+DataName+\"_UMAP.pdf\")\n",
    "fig, ax = plotClass(Id_Class, X_vars, Y_vars, pdf, dtp,\n",
    "          run_num = 1, n_neighbors = 20, min_dist = 0.99, \n",
    "          method = \"umap\", \n",
    "          scale = False, # scale = \"pca\", \"standard\", anything esle is taken as no scaling \n",
    "          cluster_colors = False, # chosed_color: if False, true_colors bellow must be given \n",
    "          true_colors = data_dic_orig[\"true_colors\"],# give a true class colors as dictionary with X_vars and Y_vars as key\n",
    "          markers = [(\" \",5),(\" \",5)], # optional markers list and their size for X and Y\n",
    "          show_labels = False, # optional show the labels of X and Y\n",
    "          show_orig = False, #optional show the the axis lines going through embedded origin \n",
    "          legend = True, # add legend only if true cluster are required\n",
    "          wrap_true = True, # wrapp the members of a true cluster , in each indentified clusters\n",
    "          group_annot_size = 15, ### size of the annotations in the center of polygones‚\n",
    "          wrap_predicted = True, # full lines to wrap around the predicted cluster\n",
    "          show_pred_outliers = False, #\n",
    "          def_pred_outliers = (3, 0.95), # (a, b), greater than a*std of pairwise dist for more than b*100% of the points in the predicted class\n",
    "          oultiers_markers = (\"P\", \"^\", 5), # (true, predicted, size)\n",
    "          wrap_type = \"convexhull\", # convexhull or ellipse (ellipse does not look accurate)\n",
    "          dataname = \"Dist\") # true cluster markers for this simulation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.legend(loc = (1,1), fontsize = 15, ncol = 3)\n",
    "plt.legend(loc = (0,1), fontsize = 9, ncol = 10)\n",
    "pdf.savefig(fig, bbox_inches = \"tight\")\n",
    "pdf.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6424c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"2-Dimensional visualization visualization of clusters (UMAP visualization) \n",
    "- separated predicted classes \n",
    "- wrapped true classes\n",
    "\"\"\"\n",
    "pdf2= PdfPages(\"Figures/Final/\"+DataName+\"_UMAP.pdf\")\n",
    "fig2, ax = plotClass_separated(Id_Class, X_vars, Y_vars, pdf, dtp,\n",
    "          run_num = 1, n_neighbors = 20, min_dist = 0.99, \n",
    "          method = \"umap\", \n",
    "          scale = False, # scale = \"pca\", \"standard\", anything esle is taken as no scaling \n",
    "          cluster_colors = False, # chosed_color: if False, true_colors bellow must be given \n",
    "          true_colors = data_dic_orig[\"true_colors\"],# give a true class colors as dictionary with X_vars and Y_vars as key\n",
    "          markers = [(\" \",20),(\" \",20)], # optional markers list and their size for X and Y\n",
    "          show_labels = False, # optional show the labels of X and Y\n",
    "          show_orig = False, #optional show the the axis lines going through embedded origin \n",
    "          legend = False, # add legend only if true cluster are required\n",
    "          wrap_true = True, # wrapp the members of a true cluster , in each indentified clusters\n",
    "          group_annot_size = 35, ### size of the annotations in the center of polygones‚\n",
    "          group_color = \"black\", ### color of cluster annotatations (if None then true colors)\n",
    "          wrap_predicted = False, # full lines to wrap around the predicted cluster (excluding some outliers)\n",
    "          wrap_pred_params = (\"black\", 3), ### optional for pred wrap (color, linewidth)\n",
    "          show_pred_outliers = False, \n",
    "          def_pred_outliers = (3.25, 0.75), # (a, b), greater than a*std of pairwise dist for more than b*100% of the points in the predicted class\n",
    "          oultiers_markers = (\"P\", \"^\", 15), # (true, predicted, size)\n",
    "          wrap_type = \"convexhull\", # convexhull or ellipse (ellipse does not look accurate)\n",
    "          points_hull = 3, ## threshold for connecting points in convex hull\n",
    "          dataname = \"Dist\",# true cluster markers for this simulation\n",
    "          show_separation = True, ### show axis to clearly separate all predicted clusters\n",
    "          num_row_col = (4, 10),\n",
    "          alpha = 0.25) \n",
    "\n",
    "pdf2.savefig(fig2, bbox_inches = \"tight\")\n",
    "\n",
    "\"\"\"2-Dimensional visualization visualization of clusters (UMAP visualization) \n",
    "- separated predicted classes \n",
    "- colored true classes\n",
    "\"\"\"\n",
    "fig, ax = plotClass_separated_ver0(Id_Class, X_vars, Y_vars, pdf, dtp,\n",
    "          run_num = 1, n_neighbors = 20, min_dist = 0.99, \n",
    "          method = \"umap\",\n",
    "          scale = False, # scale = \"pca\", \"standard\", anything esle is taken as no scaling \n",
    "          cluster_colors = False, # chosed_color: if False, true_colors bellow must be given \n",
    "          true_colors = data_dic_orig[\"true_colors\"], # give a true class colors as dictionary with X_vars and Y_vars as key\n",
    "          markers = [(\"o\",500),(\"^\",500)], # optional markers list and their size for X and Y\n",
    "          sub_fig_size = 10, # optional sub figure size (as a square)\n",
    "          show_labels = False, # optional show the labels of X and Y\n",
    "          show_orig = False, # optional show the the axis lines going through origin \n",
    "          show_separation = True, # optional separate all subfigs\n",
    "          num_row_col = (4, 10),  # number of subfigs in row and col\n",
    "          dataname = \"Dist\",# true cluster markers for this simulation\n",
    "          ) \n",
    "\n",
    "pdf2.savefig(fig, bbox_inches = \"tight\")\n",
    "pdf2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffab608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2-Dimensional visualization of clusters (TSNE visualization) \n",
    "- all predicted classes \n",
    "- colored predicted classes or true classes\n",
    "\"\"\"\n",
    "pdf= PdfPages(\"Figures/\"+DataName+\"_TSNE.pdf\")\n",
    "fig, ax = plotClass(Id_Class, X_vars, Y_vars, pdf, dtp,\n",
    "          run_num = 1, n_neighbors = 15, \n",
    "          method = \"t-SNE\", scale = False, # scale = \"pca\", \"standard\", anything esle is taken as no scaling \n",
    "          cluster_colors = False, # chosed_color: if False, true_colors bellow must be given \n",
    "          true_colors = data_dic_orig[\"true_colors\"],# give a true class colors as dictionary with X_vars and Y_vars as key\n",
    "          markers = [(\"o\",20),(\"o\",20)], # optional markers list and their size for X and Y\n",
    "          legend = False, # add legend only if true cluster are required\n",
    "          show_labels = False, # optional show the labels of X and Y\n",
    "          show_orig = True)# optional show the the axis lines going through origin \n",
    "plt.show()\n",
    "pdf.savefig(fig, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753aae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2-Dimensional visualization of MIASA clusters (TSNE visualization) \n",
    "- separated predicted classes \n",
    "- colored true classes\n",
    "\"\"\"\n",
    "plotClass_separated(Id_Class, X_vars, Y_vars, pdf, dtp,\n",
    "          run_num = 1, n_neighbors = 15, \n",
    "          method = \"t-SNE\", \n",
    "          scale = False, # scale = \"pca\", \"standard\", anything esle is taken as no scaling \n",
    "          cluster_colors = False, # chosed_color: if False, true_colors bellow must be given \n",
    "          true_colors = data_dic_orig[\"true_colors\"], # give a true class colors as dictionary with X_vars and Y_vars as key\n",
    "          markers = [(\"o\",100),(\"o\",100)], # optional markers list and their size for X and Y\n",
    "          sub_fig_size = 10, # optional sub figure size (as a square)\n",
    "          show_labels = False, # optional show the labels of X and Y\n",
    "          show_orig = False, # optional show the the axis lines going through origin\n",
    "          show_separation = True, # optional separate all subfigs\n",
    "          num_row_col = (20, 2) )  # number of subfigs in row and col\n",
    "\n",
    "pdf.savefig(fig, bbox_inches = \"tight\")\n",
    "pdf.close() # save everything                \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f157a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Perform analogue non-metric: extract the classification, \n",
    "MDS methods based on the distance matrix can be used for visualization (e.g. sklearn.manifold.MDS or t-SNE). \n",
    "\"\"\"\n",
    "from Methods.NonMD_class import NonMetric_Class\n",
    "Id_Class_2 = NonMetric_Class(X, Y, num_clust_test, \n",
    "                       dist_origin = dist_origin,  # including distance to origin is the same as clustering over true feature norm\n",
    "                       metric_method = metric_method, \n",
    "                       clust_method = \"Kmedoids\", # clustering is based on distance matrix including info in dist_origin (it is not Euclidean thus we can't use Kmeans)\n",
    "                        Feature_dic = Feature_dic,\n",
    "                       in_threads = in_threads,\n",
    "                       palette = palette_pred)\n",
    "\n",
    "print(\"------------- Evaluate clustering ------------\")\n",
    "accuracy_2b = rand_score(Class_True, Id_Class_2[\"Class_pred\"])\n",
    "accuracy_3b = adjusted_rand_score(Class_True, Id_Class_2[\"Class_pred\"])\n",
    "print(\"Rand Index\", accuracy_2b, \"\\nAdjusted Rand_Index\", accuracy_3b)\n",
    "\n",
    "\"\"\"\n",
    "2-Dimensional visualization of clusters (MDS visualization) \n",
    "- all predicted classes \n",
    "- colored predicted classes \n",
    "\"\"\"\n",
    "nonMD_low = \"t-SNE\"\n",
    "pdf = PdfPages(\"Figures/\"+DataName+\"_NonMD_%s.pdf\"%nonMD_low)\n",
    "plotClass(Id_Class, X_vars, Y_vars, pdf, dtp,\n",
    "          run_num = 1, n_neighbors = 15,\n",
    "          method = nonMD_low, \n",
    "          scale = False, # scale = \"pca\", \"standard\", anything esle is taken as no scaling \n",
    "          cluster_colors = True, # chosed_color: if False, true_colors bellow must be given \n",
    "          true_colors = False,# give a true class colors as dictionary with X_vars and Y_vars as key\n",
    "          markers = [(\"o\",20),(\"o\",20)], # optional markers list and their size for X and Y\n",
    "          show_labels = False, # optional show the labels of X and Y\n",
    "          show_orig = True, # optional show the the axis lines going through origin  \n",
    "          metric = \"precomputed\") # Necessary option for non-Metric, use Distance matrix\n",
    "pdf.savefig(fig, bbox_inches = \"tight\")\n",
    "pdf.close()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "macPy3",
   "language": "python",
   "name": "macpy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
